{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of this file\n",
    "\n",
    "In this file, I will hydrate tweets from this resource: https://ieee-dataport.org/open-access/coronavirus-covid-19-geo-tagged-tweets-dataset\n",
    "\n",
    "This resource contains a subset of tweets, scraped every day since March 20th, that have geolocation data. \n",
    "\n",
    "We can use code from \"get_location_from_geocoordinates.py\" in order to see how to use lat/long info to get a person's location. \n",
    "\n",
    "For this first pass, we'll use the following dates:\n",
    "\n",
    "1. (NOTE: not using this date, since for this dataset we don't have data from this date) March 9th: Governor DeSantis declares a State of Emergency\n",
    "2. April 17th: DeSantis issues a statewide stay-at-home order following growing pressure to do so\n",
    "3. May 18th: DeSantis says that Florida will begin full phase one of reopening, allowing gyms and restaurants to operate at 50% capacity, starting May 18.\n",
    "4. June 5th: DeSantis announces that Florida could move into Phase 2 except south Florida, specifically Miami-Dade, Broward, and Palm Beach, which need to submit plans for reopening. Phase 2 in Florida begins, with bars allowed to open at 50% capacity with social distancing and sanitation.\n",
    "5. July 2nd: Florida reports 10,000 new coronavirus cases in a single day, the biggest one-day increase in the state since the pandemic started, and more than any European country had at the height of their outbreaks.\n",
    "6. September 25th: Governor Ron DeSantis fully opened the state of Florida by executive order on Friday. The order also prohibits local governments from imposing fines or shutting down businesses, or enforcing mask mandates\n",
    "7. October 17th: Florida reported its highest COVID19 numbers in two onths. The seven-day average was more than 3,300 cases. Reporting anomalies made it more difficult to gather statistical trends. Positivity rate was 5.2%, with over 2,000 hospitalizations. \n",
    "8. December 17th:  Florida reported 13,148 new cases, largest since July 16th\n",
    "\n",
    "All these dates correspond with important COVID-related events in Florida. I chose Florida since it's had a large range of different COVID-related events (e.g., openings, closings, shutdowns, etc.), rather than some other states that, say, had an initial lockdown and stayed in lockdown. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime as datetime\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "\n",
    "pd.set_option('display.max_columns', None) # show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load tweets\n",
    "\n",
    "Due to sharing restrictions, the public dataset doesn't have the actual tweets themselves. Rather, it has the tweet IDs. Therefore, we can \"hydrate\" the tweet IDs to recover the actual tweets\n",
    "\n",
    "(Also, accessing the tweets requires an IEEE account, so the link might not work in the future? Accessing the tweets is easy with the website link above, however). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect tweets from April 16th to April 17th\n",
    "april16_17 = pd.read_csv(\"https://ieee-dataport.s3.amazonaws.com/open/14206/april16_april17.csv?response-content-disposition=attachment%3B%20filename%3D%22april16_april17.csv%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJOHYI4KJCE6Q7MIQ%2F20201217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201217T223856Z&X-Amz-SignedHeaders=Host&X-Amz-Expires=86400&X-Amz-Signature=c4fbf41e249dc1fb9f5f7be962a2ca05d5210d0a9a81293820f49c91efed3826\", \n",
    "                         names = [\"tweet_id\", \"sentiment_score\"])\n",
    "\n",
    "# collect tweets from April 17th to April 18th\n",
    "april17_18 = pd.read_csv(\"https://ieee-dataport.s3.amazonaws.com/open/14206/april17_april18.csv?response-content-disposition=attachment%3B%20filename%3D%22april17_april18.csv%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJOHYI4KJCE6Q7MIQ%2F20201217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201217T223856Z&X-Amz-SignedHeaders=Host&X-Amz-Expires=86400&X-Amz-Signature=db65792c9a01221fd2e70f90dfa5dcbc2b5fd9649311e7ee6b11e810c69c0c60\", \n",
    "                          names = [\"tweet_id\", \"sentiment_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250641596887990272</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250646705516707840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250647034253709315</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1250655078744240134</td>\n",
       "      <td>0.170455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250655491904147456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  sentiment_score\n",
       "0  1250641596887990272         0.125000\n",
       "1  1250646705516707840         0.000000\n",
       "2  1250647034253709315         0.000000\n",
       "3  1250655078744240134         0.170455\n",
       "4  1250655491904147456         0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "april16_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "april17 = pd.concat([april16_17, april17_18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250641596887990272</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250646705516707840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250647034253709315</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1250655078744240134</td>\n",
       "      <td>0.170455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250655491904147456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1251359682712616961</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1251360432079634434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1251364103618248705</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1251366441015803912</td>\n",
       "      <td>-0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1251367315117047808</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  sentiment_score\n",
       "0    1250641596887990272         0.125000\n",
       "1    1250646705516707840         0.000000\n",
       "2    1250647034253709315         0.000000\n",
       "3    1250655078744240134         0.170455\n",
       "4    1250655491904147456         0.000000\n",
       "..                   ...              ...\n",
       "368  1251359682712616961         0.000000\n",
       "369  1251360432079634434         0.000000\n",
       "370  1251364103618248705        -0.050000\n",
       "371  1251366441015803912        -0.004444\n",
       "372  1251367315117047808         0.000000\n",
       "\n",
       "[816 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "april17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "april17.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can export these tweet IDs in a .csv file, and then we can use twarc, a command line Python tool, to get the tweets that we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = list(april17[\"tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_ID_DIR = \"../../data/tweets/tweet_ids/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TWEET_ID_DIR + \"april17_tweets.csv\", 'a+') as f: # a+ lets us both append and write\n",
    "    for idx, tweet in enumerate(tweet_ids):\n",
    "        if idx != len(tweet_ids) - 1:\n",
    "            f.write(f\"{tweet},\\n\")\n",
    "        else:\n",
    "            f.write(f\"{tweet}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using these tweet IDs, let's hydrate them to recover the original tweets\n",
    "\n",
    "First, you have to confirm your credentials. \n",
    "\n",
    "`twarc configure`\n",
    "\n",
    "Then, submit the creds. After doing so successfully, you should get a message like this: \n",
    "\n",
    "`The credentials for default have been saved to your configuration file at /Users/mark/.twarc`\n",
    "\n",
    "Afterwards, you can start hydrating the tweets. \n",
    "\n",
    "This can be done in the command line\n",
    "\n",
    "You'd run something like this:\n",
    "\n",
    "`twarc hydrate ids.txt > tweets.jsonl`\n",
    "\n",
    "In my case, running the command from the root directory of this project, it looks something like this:\n",
    "\n",
    "`twarc hydrate data/tweets/tweet_ids/april17_tweets.csv > data/tweets/hydrated_tweets/april17_tweets.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYDRATED_TWEETS_DIR = \"../../data/tweets/hydrated_tweets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's convert the .jsonl file into a .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['april17_tweets.jsonl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(HYDRATED_TWEETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonObj = pd.read_json(path_or_buf=HYDRATED_TWEETS_DIR + \"april17_tweets.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '495a55057ac886b9',\n",
       " 'url': 'https://api.twitter.com/1.1/geo/id/495a55057ac886b9.json',\n",
       " 'place_type': 'city',\n",
       " 'name': 'Montpelier',\n",
       " 'full_name': 'Montpelier, VT',\n",
       " 'country_code': 'US',\n",
       " 'country': 'United States',\n",
       " 'contained_within': [],\n",
       " 'bounding_box': {'type': 'Polygon',\n",
       "  'coordinates': [[[-72.6255728, 44.2348719],\n",
       "    [-72.544556, 44.2348719],\n",
       "    [-72.544556, 44.3127017],\n",
       "    [-72.6255728, 44.3127017]]]},\n",
       " 'attributes': {}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonObj[\"place\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>user</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>contributors</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>extended_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-16 04:26:07+00:00</td>\n",
       "      <td>1250641596887990272</td>\n",
       "      <td>1250641596887990272</td>\n",
       "      <td>Finally got to a color I love and a length I’m...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 240]</td>\n",
       "      <td>{'hashtags': [{'text': 'quarantine', 'indices'...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 32545952, 'id_str': '32545952', 'name':...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [44.15253213,...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-72.5981195,...</td>\n",
       "      <td>{'id': '495a55057ac886b9', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-16 04:46:25+00:00</td>\n",
       "      <td>1250646705516707840</td>\n",
       "      <td>1250646705516707840</td>\n",
       "      <td>#wutang #wutangforever #corona @ Downtown Los ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 77]</td>\n",
       "      <td>{'hashtags': [{'text': 'wutang', 'indices': [0...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 15293534, 'id_str': '15293534', 'name':...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [34.03742524,...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-118.2487404...</td>\n",
       "      <td>{'id': '3b77caf94bfc81fe', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-16 04:47:43+00:00</td>\n",
       "      <td>1250647034253709315</td>\n",
       "      <td>1250647034253709312</td>\n",
       "      <td>Swirling again @ Corona, California https://t....</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 59]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 3283791091, 'id_str': '3283791091', 'na...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [33.8753, -11...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-117.566, 33...</td>\n",
       "      <td>{'id': '5e4b6834e36e68fa', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16 05:19:41+00:00</td>\n",
       "      <td>1250655078744240134</td>\n",
       "      <td>1250655078744240128</td>\n",
       "      <td>Does it feel like you want to #Crawl on the wa...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 240]</td>\n",
       "      <td>{'hashtags': [{'text': 'Crawl', 'indices': [30...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 392875184, 'id_str': '392875184', 'name...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [59.3307, 18....</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [18.0605, 59....</td>\n",
       "      <td>{'id': 'd56c5babcffde8ef', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-16 05:21:19+00:00</td>\n",
       "      <td>1250655491904147456</td>\n",
       "      <td>1250655491904147456</td>\n",
       "      <td>Get your stanky booty to Cave Creek &amp;amp; Care...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 184]</td>\n",
       "      <td>{'hashtags': [{'text': 'walmart', 'indices': [...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 524860845, 'id_str': '524860845', 'name...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [33.8304, -11...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-111.964, 33...</td>\n",
       "      <td>{'id': '005e9bd60c4f1337', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2020-04-16 04:26:07+00:00  1250641596887990272  1250641596887990272   \n",
       "1 2020-04-16 04:46:25+00:00  1250646705516707840  1250646705516707840   \n",
       "2 2020-04-16 04:47:43+00:00  1250647034253709315  1250647034253709312   \n",
       "3 2020-04-16 05:19:41+00:00  1250655078744240134  1250655078744240128   \n",
       "4 2020-04-16 05:21:19+00:00  1250655491904147456  1250655491904147456   \n",
       "\n",
       "                                           full_text  truncated  \\\n",
       "0  Finally got to a color I love and a length I’m...      False   \n",
       "1  #wutang #wutangforever #corona @ Downtown Los ...      False   \n",
       "2  Swirling again @ Corona, California https://t....      False   \n",
       "3  Does it feel like you want to #Crawl on the wa...      False   \n",
       "4  Get your stanky booty to Cave Creek &amp; Care...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0           [0, 240]  {'hashtags': [{'text': 'quarantine', 'indices'...   \n",
       "1            [0, 77]  {'hashtags': [{'text': 'wutang', 'indices': [0...   \n",
       "2            [0, 59]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "3           [0, 240]  {'hashtags': [{'text': 'Crawl', 'indices': [30...   \n",
       "4           [0, 184]  {'hashtags': [{'text': 'walmart', 'indices': [...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"http://instagram.com\" rel=\"nofollow\">...                    NaN   \n",
       "1  <a href=\"http://instagram.com\" rel=\"nofollow\">...                    NaN   \n",
       "2  <a href=\"http://instagram.com\" rel=\"nofollow\">...                    NaN   \n",
       "3  <a href=\"http://instagram.com\" rel=\"nofollow\">...                    NaN   \n",
       "4  <a href=\"http://instagram.com\" rel=\"nofollow\">...                    NaN   \n",
       "\n",
       "   in_reply_to_status_id_str  in_reply_to_user_id  in_reply_to_user_id_str  \\\n",
       "0                        NaN                  NaN                      NaN   \n",
       "1                        NaN                  NaN                      NaN   \n",
       "2                        NaN                  NaN                      NaN   \n",
       "3                        NaN                  NaN                      NaN   \n",
       "4                        NaN                  NaN                      NaN   \n",
       "\n",
       "  in_reply_to_screen_name                                               user  \\\n",
       "0                    None  {'id': 32545952, 'id_str': '32545952', 'name':...   \n",
       "1                    None  {'id': 15293534, 'id_str': '15293534', 'name':...   \n",
       "2                    None  {'id': 3283791091, 'id_str': '3283791091', 'na...   \n",
       "3                    None  {'id': 392875184, 'id_str': '392875184', 'name...   \n",
       "4                    None  {'id': 524860845, 'id_str': '524860845', 'name...   \n",
       "\n",
       "                                                 geo  \\\n",
       "0  {'type': 'Point', 'coordinates': [44.15253213,...   \n",
       "1  {'type': 'Point', 'coordinates': [34.03742524,...   \n",
       "2  {'type': 'Point', 'coordinates': [33.8753, -11...   \n",
       "3  {'type': 'Point', 'coordinates': [59.3307, 18....   \n",
       "4  {'type': 'Point', 'coordinates': [33.8304, -11...   \n",
       "\n",
       "                                         coordinates  \\\n",
       "0  {'type': 'Point', 'coordinates': [-72.5981195,...   \n",
       "1  {'type': 'Point', 'coordinates': [-118.2487404...   \n",
       "2  {'type': 'Point', 'coordinates': [-117.566, 33...   \n",
       "3  {'type': 'Point', 'coordinates': [18.0605, 59....   \n",
       "4  {'type': 'Point', 'coordinates': [-111.964, 33...   \n",
       "\n",
       "                                               place  contributors  \\\n",
       "0  {'id': '495a55057ac886b9', 'url': 'https://api...           NaN   \n",
       "1  {'id': '3b77caf94bfc81fe', 'url': 'https://api...           NaN   \n",
       "2  {'id': '5e4b6834e36e68fa', 'url': 'https://api...           NaN   \n",
       "3  {'id': 'd56c5babcffde8ef', 'url': 'https://api...           NaN   \n",
       "4  {'id': '005e9bd60c4f1337', 'url': 'https://api...           NaN   \n",
       "\n",
       "   is_quote_status  retweet_count  favorite_count  favorited  retweeted  \\\n",
       "0            False              0               0      False      False   \n",
       "1            False              0               0      False      False   \n",
       "2            False              0               0      False      False   \n",
       "3            False              0               0      False      False   \n",
       "4            False              0               1      False      False   \n",
       "\n",
       "   possibly_sensitive lang  quoted_status_id  quoted_status_id_str  \\\n",
       "0                 0.0   en               NaN                   NaN   \n",
       "1                 0.0   en               NaN                   NaN   \n",
       "2                 0.0   en               NaN                   NaN   \n",
       "3                 0.0   en               NaN                   NaN   \n",
       "4                 0.0   en               NaN                   NaN   \n",
       "\n",
       "  quoted_status_permalink quoted_status extended_entities  \n",
       "0                     NaN           NaN               NaN  \n",
       "1                     NaN           NaN               NaN  \n",
       "2                     NaN           NaN               NaN  \n",
       "3                     NaN           NaN               NaN  \n",
       "4                     NaN           NaN               NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonObj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start processing tweets, getting the info that we care about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We likely only care about the following columns:\n",
    "\n",
    "    • created_at\n",
    "    • id\n",
    "    • full_text\n",
    "    • geo\n",
    "    • coordinates\n",
    "    • place (this has the city + state location, as a field called \"full_name\")\n",
    "    • retweet_count\n",
    "    • favorite_count\n",
    "    \n",
    "We also want to parse the \"created_at\" column (we can perhaps create 2 columns, one with the date and one with the hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jsonObj[[\"created_at\", \"id\", \"full_text\", \"geo\", \"coordinates\", \"place\", \"retweet_count\", \"favorite_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montpelier, VT'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"place\"][0][\"full_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CA'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"place\"][1][\"full_name\"].split(\",\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3b77caf94bfc81fe',\n",
       " 'url': 'https://api.twitter.com/1.1/geo/id/3b77caf94bfc81fe.json',\n",
       " 'place_type': 'city',\n",
       " 'name': 'Los Angeles',\n",
       " 'full_name': 'Los Angeles, CA',\n",
       " 'country_code': 'US',\n",
       " 'country': 'United States',\n",
       " 'contained_within': [],\n",
       " 'bounding_box': {'type': 'Polygon',\n",
       "  'coordinates': [[[-118.668404, 33.704538],\n",
       "    [-118.155409, 33.704538],\n",
       "    [-118.155409, 34.337041],\n",
       "    [-118.668404, 34.337041]]]},\n",
       " 'attributes': {}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"place\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each tweet, let's get the states that they're in. We have a `place` column that has a dictionary with place information. For the tweets in the USA, we can get state-level information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_from_location(place):\n",
    "    \"\"\"\n",
    "    Gets state info from place field\n",
    "    Assumes dict input\n",
    "    \"\"\"\n",
    "    \n",
    "    if place is None:\n",
    "        state = \"NA\"  \n",
    "    elif place[\"country_code\"] != \"US\":\n",
    "        state = \"NA\"\n",
    "    else:\n",
    "        state = place[\"full_name\"].split(\",\")[1].strip() # e.g., \"Los Angeles, CA\" --> \"CA\"\n",
    "        \n",
    "    return state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '495a55057ac886b9', 'url': 'https://api.twitter.com/1.1/geo/id/495a55057ac886b9.json', 'place_type': 'city', 'name': 'Montpelier', 'full_name': 'Montpelier, VT', 'country_code': 'US', 'country': 'United States', 'contained_within': [], 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-72.6255728, 44.2348719], [-72.544556, 44.2348719], [-72.544556, 44.3127017], [-72.6255728, 44.3127017]]]}, 'attributes': {}}\n",
      "-==============\n",
      "{'id': '3b77caf94bfc81fe', 'url': 'https://api.twitter.com/1.1/geo/id/3b77caf94bfc81fe.json', 'place_type': 'city', 'name': 'Los Angeles', 'full_name': 'Los Angeles, CA', 'country_code': 'US', 'country': 'United States', 'contained_within': [], 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-118.668404, 33.704538], [-118.155409, 33.704538], [-118.155409, 34.337041], [-118.668404, 34.337041]]]}, 'attributes': {}}\n",
      "-==============\n",
      "{'id': '5e4b6834e36e68fa', 'url': 'https://api.twitter.com/1.1/geo/id/5e4b6834e36e68fa.json', 'place_type': 'city', 'name': 'Corona', 'full_name': 'Corona, CA', 'country_code': 'US', 'country': 'United States', 'contained_within': [], 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-117.672915, 33.802102], [-117.498401, 33.802102], [-117.498401, 33.916084], [-117.672915, 33.916084]]]}, 'attributes': {}}\n",
      "-==============\n"
     ]
    }
   ],
   "source": [
    "for idx, location_dict in enumerate(df[\"place\"]):\n",
    "    if idx > 2:\n",
    "        break\n",
    "    print(location_dict)\n",
    "    print(\"-==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location_dict in df[\"place\"]:\n",
    "    try:\n",
    "        states.append(get_state_from_location(location_dict))\n",
    "    except Exception as e:\n",
    "        print(location_dict)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798, 8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[\"US_state\"] = states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA     486\n",
       "CA      85\n",
       "NY      47\n",
       "TX      24\n",
       "USA     23\n",
       "FL      20\n",
       "IL      10\n",
       "GA      10\n",
       "NJ       7\n",
       "AZ       6\n",
       "PA       6\n",
       "OH       6\n",
       "IN       5\n",
       "MD       5\n",
       "SC       5\n",
       "TN       5\n",
       "DC       4\n",
       "LA       3\n",
       "NV       3\n",
       "AL       3\n",
       "WA       3\n",
       "CO       3\n",
       "VT       3\n",
       "NC       3\n",
       "IA       2\n",
       "MA       2\n",
       "UT       2\n",
       "WI       2\n",
       "MO       2\n",
       "CT       2\n",
       "OR       1\n",
       "KY       1\n",
       "MS       1\n",
       "VA       1\n",
       "ID       1\n",
       "HI       1\n",
       "MI       1\n",
       "MN       1\n",
       "NE       1\n",
       "RI       1\n",
       "OK       1\n",
       "Name: US_state, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"US_state\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have locations, let's also get the dates of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>US_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-16 04:26:07+00:00</td>\n",
       "      <td>1250641596887990272</td>\n",
       "      <td>Finally got to a color I love and a length I’m...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [44.15253213,...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-72.5981195,...</td>\n",
       "      <td>{'id': '495a55057ac886b9', 'url': 'https://api...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-16 04:46:25+00:00</td>\n",
       "      <td>1250646705516707840</td>\n",
       "      <td>#wutang #wutangforever #corona @ Downtown Los ...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [34.03742524,...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-118.2487404...</td>\n",
       "      <td>{'id': '3b77caf94bfc81fe', 'url': 'https://api...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-16 04:47:43+00:00</td>\n",
       "      <td>1250647034253709315</td>\n",
       "      <td>Swirling again @ Corona, California https://t....</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [33.8753, -11...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-117.566, 33...</td>\n",
       "      <td>{'id': '5e4b6834e36e68fa', 'url': 'https://api...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16 05:19:41+00:00</td>\n",
       "      <td>1250655078744240134</td>\n",
       "      <td>Does it feel like you want to #Crawl on the wa...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [59.3307, 18....</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [18.0605, 59....</td>\n",
       "      <td>{'id': 'd56c5babcffde8ef', 'url': 'https://api...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-16 05:21:19+00:00</td>\n",
       "      <td>1250655491904147456</td>\n",
       "      <td>Get your stanky booty to Cave Creek &amp;amp; Care...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [33.8304, -11...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-111.964, 33...</td>\n",
       "      <td>{'id': '005e9bd60c4f1337', 'url': 'https://api...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0 2020-04-16 04:26:07+00:00  1250641596887990272   \n",
       "1 2020-04-16 04:46:25+00:00  1250646705516707840   \n",
       "2 2020-04-16 04:47:43+00:00  1250647034253709315   \n",
       "3 2020-04-16 05:19:41+00:00  1250655078744240134   \n",
       "4 2020-04-16 05:21:19+00:00  1250655491904147456   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Finally got to a color I love and a length I’m...   \n",
       "1  #wutang #wutangforever #corona @ Downtown Los ...   \n",
       "2  Swirling again @ Corona, California https://t....   \n",
       "3  Does it feel like you want to #Crawl on the wa...   \n",
       "4  Get your stanky booty to Cave Creek &amp; Care...   \n",
       "\n",
       "                                                 geo  \\\n",
       "0  {'type': 'Point', 'coordinates': [44.15253213,...   \n",
       "1  {'type': 'Point', 'coordinates': [34.03742524,...   \n",
       "2  {'type': 'Point', 'coordinates': [33.8753, -11...   \n",
       "3  {'type': 'Point', 'coordinates': [59.3307, 18....   \n",
       "4  {'type': 'Point', 'coordinates': [33.8304, -11...   \n",
       "\n",
       "                                         coordinates  \\\n",
       "0  {'type': 'Point', 'coordinates': [-72.5981195,...   \n",
       "1  {'type': 'Point', 'coordinates': [-118.2487404...   \n",
       "2  {'type': 'Point', 'coordinates': [-117.566, 33...   \n",
       "3  {'type': 'Point', 'coordinates': [18.0605, 59....   \n",
       "4  {'type': 'Point', 'coordinates': [-111.964, 33...   \n",
       "\n",
       "                                               place  retweet_count  \\\n",
       "0  {'id': '495a55057ac886b9', 'url': 'https://api...              0   \n",
       "1  {'id': '3b77caf94bfc81fe', 'url': 'https://api...              0   \n",
       "2  {'id': '5e4b6834e36e68fa', 'url': 'https://api...              0   \n",
       "3  {'id': 'd56c5babcffde8ef', 'url': 'https://api...              0   \n",
       "4  {'id': '005e9bd60c4f1337', 'url': 'https://api...              0   \n",
       "\n",
       "   favorite_count US_state  \n",
       "0               0       VT  \n",
       "1               0       CA  \n",
       "2               0       CA  \n",
       "3               0       NA  \n",
       "4               1       AZ  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "months = []\n",
    "days = []\n",
    "hours = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format = \"2020-04-16\"\n",
    "\n",
    "for timestamp in df[\"created_at\"]:\n",
    "    hour = pd.to_datetime(timestamp).hour\n",
    "    dt_obj = pd.to_datetime(timestamp).date()\n",
    "    year = dt_obj.year\n",
    "    month = dt_obj.month\n",
    "    day = dt_obj.day\n",
    "    \n",
    "    hours.append(hour)\n",
    "    months.append(month)\n",
    "    days.append(day)\n",
    "    \n",
    "    if month < 10:\n",
    "        month = f\"0{month}\"\n",
    "    \n",
    "    dates.append(f\"{year}-{month}-{day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df[\"date_of_tweet\"] = dates\n",
    "df[\"month_of_tweet\"] = months\n",
    "df[\"day_of_tweet\"] = days\n",
    "df[\"hour_of_tweet\"] = hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse the full text and check for counts of certain words as well. \n",
    "\n",
    "Let's do the following:\n",
    "\n",
    "Cleaning steps:\n",
    "\n",
    "1. Remove punctuation\n",
    "2. Do string split\n",
    "3. Remove links\n",
    "\n",
    "Processing:\n",
    "1. Make all the words lowercase\n",
    "2. Remove stopwords\n",
    "3. Stem/lemmatize (maybe?)\n",
    "\n",
    "Then, for analysis,\n",
    "\n",
    "1. Create a new column for all the hashtags (and add all the hashtags, per tweet)\n",
    "2. Do word counts of specific words\n",
    "3. Do LDA/topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION ='''!()-[]{};:'\"\\,<>./?@$%^&*_~''' # keep hashtags\n",
    "STOPWORDS = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    text = text.encode(\"utf-8\")\n",
    "    allchars = [str for str in text.decode('utf-8')]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.decode('utf-8').split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        Removes punctuation, does string split, and removes links\n",
    "    \"\"\"\n",
    "    \n",
    "    return_arr = []\n",
    "    \n",
    "    # remove punctuation\n",
    "    text_no_punctuation = \"\"\n",
    "    \n",
    "    for char in text:\n",
    "        if char not in PUNCTUATION:\n",
    "            text_no_punctuation = text_no_punctuation + char\n",
    "            \n",
    "    # remove emojis\n",
    "    text_no_punctuation = remove_emoji(text_no_punctuation)\n",
    "    text_no_punctuation = re.sub(r'\\\\U[a-zA-Z0-9]{8}', '', text_no_punctuation)\n",
    "    \n",
    "    # remove \\n and \\t\n",
    "    text_no_punctuation = re.sub(r'\\n', '', text_no_punctuation)\n",
    "    text_no_punctuation = re.sub(r'\\t', '', text_no_punctuation)\n",
    "    \n",
    "    # remove escape sequences\n",
    "    text_no_escape = \"\"\n",
    "    \n",
    "    for char in text_no_punctuation:\n",
    "        try:\n",
    "            char.encode('ascii')\n",
    "            text_no_escape = text_no_escape + char # this'll catch chars that don't have an ascii equivalent (e.g., emojis)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # add space between # and another char before it (e.g., split yes#baseball into yes #baseball)\n",
    "    text_no_escape = re.sub(r\"([a-zA-Z0-9]){1}#\", r\"\\1 #\", text_no_escape)\n",
    "    \n",
    "    # other preprocessing\n",
    "    text_arr = text_no_escape.split(' ')\n",
    "    \n",
    "    for word in text_arr:\n",
    "        \n",
    "        # clean words\n",
    "        word = word.lower()\n",
    "        \n",
    "        if \"http\" not in word and word.strip() != '' and word not in STOPWORDS:\n",
    "            return_arr.append(word)\n",
    "            \n",
    "    return return_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[\"cleaned_text\"] = df[\"full_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's deal with hashtags. Let's create a new column that contains all the hashtags, a column that counts how many hashtags there are, and a third column that has the text array (tokenized text) without hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_arr = []\n",
    "num_hashtags_arr = []\n",
    "text_no_hashtags_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokenized_text in df[\"cleaned_text\"]:\n",
    "    hashtag_lst = []\n",
    "    text_no_hashtags_lst = []\n",
    "    \n",
    "    for word in tokenized_text:\n",
    "        if '#' in word:\n",
    "            hashtag_lst.append(word)\n",
    "        else:\n",
    "            text_no_hashtags_lst.append(word)\n",
    "    \n",
    "    hashtags_arr.append(hashtag_lst)\n",
    "    num_hashtags_arr.append(len(hashtag_lst))\n",
    "    text_no_hashtags_arr.append(text_no_hashtags_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/mark/opt/anaconda3/envs/twitter_venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df[\"hashtags\"] = hashtags_arr\n",
    "df[\"hashtags_count\"] = num_hashtags_arr\n",
    "df[\"cleaned_text_no_hashtags\"] = text_no_hashtags_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>cleaned_text_no_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[finally, got, color, love, length, im, okay, ...</td>\n",
       "      <td>[#quarantine, #covid, #corona, #haircolor, #ha...</td>\n",
       "      <td>11</td>\n",
       "      <td>[finally, got, color, love, length, im, okay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[#wutang, #wutangforever, #corona, downtown, l...</td>\n",
       "      <td>[#wutang, #wutangforever, #corona]</td>\n",
       "      <td>3</td>\n",
       "      <td>[downtown, los, angeles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[swirling, corona, california]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[swirling, corona, california]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[feel, like, want, #crawl, walls, get, heres, ...</td>\n",
       "      <td>[#crawl, #quarantine, #staygolden, #staysafe, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[feel, like, want, walls, get, heres, dont, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[get, stanky, booty, cave, creek, amp, carefre...</td>\n",
       "      <td>[#walmart, #cavecreek, #toiletpaper, #quaranti...</td>\n",
       "      <td>6</td>\n",
       "      <td>[get, stanky, booty, cave, creek, amp, carefre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>[whats, say, cap, #swipeleft, #swipeleft, #run...</td>\n",
       "      <td>[#swipeleft, #swipeleft, #runnersofinstagram, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[whats, say, cap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>[#musicphillpromotions, #never, leave, home, w...</td>\n",
       "      <td>[#musicphillpromotions, #never, #mask, #protec...</td>\n",
       "      <td>8</td>\n",
       "      <td>[leave, home, without, virus, jamaica, kingsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>[home, workout, hamstringy, like, gym, still, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[home, workout, hamstringy, like, gym, still, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>[thank, much, #lukebryan, playing, dock, coron...</td>\n",
       "      <td>[#lukebryan, #countrymusic, #country, #music, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[thank, much, playing, dock, corona, virus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>[finallybeen, rough, april, 2020, expect, one,...</td>\n",
       "      <td>[#rtr, #covid19survivor]</td>\n",
       "      <td>2</td>\n",
       "      <td>[finallybeen, rough, april, 2020, expect, one,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cleaned_text  \\\n",
       "0    [finally, got, color, love, length, im, okay, ...   \n",
       "1    [#wutang, #wutangforever, #corona, downtown, l...   \n",
       "2                       [swirling, corona, california]   \n",
       "3    [feel, like, want, #crawl, walls, get, heres, ...   \n",
       "4    [get, stanky, booty, cave, creek, amp, carefre...   \n",
       "..                                                 ...   \n",
       "793  [whats, say, cap, #swipeleft, #swipeleft, #run...   \n",
       "794  [#musicphillpromotions, #never, leave, home, w...   \n",
       "795  [home, workout, hamstringy, like, gym, still, ...   \n",
       "796  [thank, much, #lukebryan, playing, dock, coron...   \n",
       "797  [finallybeen, rough, april, 2020, expect, one,...   \n",
       "\n",
       "                                              hashtags  hashtags_count  \\\n",
       "0    [#quarantine, #covid, #corona, #haircolor, #ha...              11   \n",
       "1                   [#wutang, #wutangforever, #corona]               3   \n",
       "2                                                   []               0   \n",
       "3    [#crawl, #quarantine, #staygolden, #staysafe, ...               9   \n",
       "4    [#walmart, #cavecreek, #toiletpaper, #quaranti...               6   \n",
       "..                                                 ...             ...   \n",
       "793  [#swipeleft, #swipeleft, #runnersofinstagram, ...              14   \n",
       "794  [#musicphillpromotions, #never, #mask, #protec...               8   \n",
       "795                                                 []               0   \n",
       "796  [#lukebryan, #countrymusic, #country, #music, ...              13   \n",
       "797                           [#rtr, #covid19survivor]               2   \n",
       "\n",
       "                              cleaned_text_no_hashtags  \n",
       "0    [finally, got, color, love, length, im, okay, ...  \n",
       "1                             [downtown, los, angeles]  \n",
       "2                       [swirling, corona, california]  \n",
       "3    [feel, like, want, walls, get, heres, dont, dr...  \n",
       "4    [get, stanky, booty, cave, creek, amp, carefre...  \n",
       "..                                                 ...  \n",
       "793                                  [whats, say, cap]  \n",
       "794  [leave, home, without, virus, jamaica, kingsto...  \n",
       "795  [home, workout, hamstringy, like, gym, still, ...  \n",
       "796        [thank, much, playing, dock, corona, virus]  \n",
       "797  [finallybeen, rough, april, 2020, expect, one,...  \n",
       "\n",
       "[798 rows x 4 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"cleaned_text\", \"hashtags\", \"hashtags_count\", \"cleaned_text_no_hashtags\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the columns that we'll actually use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df[[\"id\", \"full_text\", \"retweet_count\", \"favorite_count\", \n",
    "               \"US_state\", \"date_of_tweet\", \"month_of_tweet\", \"day_of_tweet\", \n",
    "               \"hour_of_tweet\", \"cleaned_text\", \"hashtags\", \"hashtags_count\", \"cleaned_text_no_hashtags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>US_state</th>\n",
       "      <th>date_of_tweet</th>\n",
       "      <th>month_of_tweet</th>\n",
       "      <th>day_of_tweet</th>\n",
       "      <th>hour_of_tweet</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>cleaned_text_no_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250641596887990272</td>\n",
       "      <td>Finally got to a color I love and a length I’m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VT</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[finally, got, color, love, length, im, okay, ...</td>\n",
       "      <td>[#quarantine, #covid, #corona, #haircolor, #ha...</td>\n",
       "      <td>11</td>\n",
       "      <td>[finally, got, color, love, length, im, okay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250646705516707840</td>\n",
       "      <td>#wutang #wutangforever #corona @ Downtown Los ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[#wutang, #wutangforever, #corona, downtown, l...</td>\n",
       "      <td>[#wutang, #wutangforever, #corona]</td>\n",
       "      <td>3</td>\n",
       "      <td>[downtown, los, angeles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250647034253709315</td>\n",
       "      <td>Swirling again @ Corona, California https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[swirling, corona, california]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[swirling, corona, california]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1250655078744240134</td>\n",
       "      <td>Does it feel like you want to #Crawl on the wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>[feel, like, want, #crawl, walls, get, heres, ...</td>\n",
       "      <td>[#crawl, #quarantine, #staygolden, #staysafe, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[feel, like, want, walls, get, heres, dont, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250655491904147456</td>\n",
       "      <td>Get your stanky booty to Cave Creek &amp;amp; Care...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>[get, stanky, booty, cave, creek, amp, carefre...</td>\n",
       "      <td>[#walmart, #cavecreek, #toiletpaper, #quaranti...</td>\n",
       "      <td>6</td>\n",
       "      <td>[get, stanky, booty, cave, creek, amp, carefre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1250641596887990272  Finally got to a color I love and a length I’m...   \n",
       "1  1250646705516707840  #wutang #wutangforever #corona @ Downtown Los ...   \n",
       "2  1250647034253709315  Swirling again @ Corona, California https://t....   \n",
       "3  1250655078744240134  Does it feel like you want to #Crawl on the wa...   \n",
       "4  1250655491904147456  Get your stanky booty to Cave Creek &amp; Care...   \n",
       "\n",
       "   retweet_count  favorite_count US_state date_of_tweet  month_of_tweet  \\\n",
       "0              0               0       VT    2020-04-16               4   \n",
       "1              0               0       CA    2020-04-16               4   \n",
       "2              0               0       CA    2020-04-16               4   \n",
       "3              0               0       NA    2020-04-16               4   \n",
       "4              0               1       AZ    2020-04-16               4   \n",
       "\n",
       "   day_of_tweet  hour_of_tweet  \\\n",
       "0            16              4   \n",
       "1            16              4   \n",
       "2            16              4   \n",
       "3            16              5   \n",
       "4            16              5   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [finally, got, color, love, length, im, okay, ...   \n",
       "1  [#wutang, #wutangforever, #corona, downtown, l...   \n",
       "2                     [swirling, corona, california]   \n",
       "3  [feel, like, want, #crawl, walls, get, heres, ...   \n",
       "4  [get, stanky, booty, cave, creek, amp, carefre...   \n",
       "\n",
       "                                            hashtags  hashtags_count  \\\n",
       "0  [#quarantine, #covid, #corona, #haircolor, #ha...              11   \n",
       "1                 [#wutang, #wutangforever, #corona]               3   \n",
       "2                                                 []               0   \n",
       "3  [#crawl, #quarantine, #staygolden, #staysafe, ...               9   \n",
       "4  [#walmart, #cavecreek, #toiletpaper, #quaranti...               6   \n",
       "\n",
       "                            cleaned_text_no_hashtags  \n",
       "0  [finally, got, color, love, length, im, okay, ...  \n",
       "1                           [downtown, los, angeles]  \n",
       "2                     [swirling, corona, california]  \n",
       "3  [feel, like, want, walls, get, heres, dont, dr...  \n",
       "4  [get, stanky, booty, cave, creek, amp, carefre...  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have these steps finalized, let's do this for the other tweets in the dates of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform same steps as above, for other tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Export tweets, with locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_venv",
   "language": "python",
   "name": "twitter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
